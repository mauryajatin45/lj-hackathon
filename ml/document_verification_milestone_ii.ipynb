{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Verification - Milestone II\n",
    "\n",
    "This notebook implements the Document Verification module for analyzing PDF documents for authenticity, extracting metadata, detecting anomalies, and providing structured verification results.\n",
    "\n",
    "Features:\n",
    "- PDF text extraction and analysis\n",
    "- Metadata extraction (dates, identifiers, parties)\n",
    "- Authenticity verification\n",
    "- Content anomaly detection\n",
    "- Structured layout analysis\n",
    "- FastAPI microservice\n",
    "\n",
    "API Endpoint: POST /verify/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install fastapi uvicorn pydantic requests pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "import logging\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Verifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentVerifier:\n",
    "    \"\"\"Main class for document verification.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Regex patterns for common fields\n",
    "        self.patterns = {\n",
    "            'agreement_no': r'AGR-\\d{5}',\n",
    "            'effective_date': r'\\d{2}-\\d{2}-\\d{4}',\n",
    "            'monetary_amount': r'\\$?\\d+(?:,\\d{3})*(?:\\.\\d{2})?',\n",
    "            'company_reg_no': r'(?:REG|CRN|REGD?\\.?)?\\s*\\d+',\n",
    "            'phone': r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}',\n",
    "            'email': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "            'url': r'https?://(?:[-\\w.])+(?:[:\\d]+)?(?:/(?:[\\w/_.])*(?:\\?(?:[\\w&=%.])*)?(?:#(?!\\w*))?)?'\n",
    "        }\n",
    "\n",
    "    def verify_document(self, input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Main verification method.\"\"\"\n",
    "        try:\n",
    "            pages = input_data.get('PAGES', [])\n",
    "            doc_meta = input_data.get('DOC_META', {})\n",
    "\n",
    "            # Extract text from pages\n",
    "            document_text = self._extract_text_from_pages(pages)\n",
    "\n",
    "            # Extract metadata\n",
    "            extracted_metadata = self._extract_metadata(document_text, doc_meta)\n",
    "\n",
    "            # Analyze structured layout\n",
    "            structured_layout = self._analyze_layout(document_text, pages)\n",
    "\n",
    "            # Detect authenticity issues\n",
    "            authenticity_issues = self._detect_authenticity_issues(extracted_metadata, structured_layout)\n",
    "\n",
    "            # Detect content issues\n",
    "            content_issues = self._detect_content_issues(document_text, extracted_metadata)\n",
    "\n",
    "            # Find suspicious snippets\n",
    "            suspicious_snippets = self._find_suspicious_snippets(document_text)\n",
    "\n",
    "            # Calculate confidence score\n",
    "            confidence_score = self._calculate_confidence_score(authenticity_issues, content_issues)\n",
    "\n",
    "            # Determine legitimacy\n",
    "            legitimate = len(authenticity_issues) == 0 and len(content_issues) == 0\n",
    "\n",
    "            result = {\n",
    "                \"confidence_score\": round(confidence_score, 2),\n",
    "                \"legitimate\": legitimate,\n",
    "                \"extracted_metadata\": extracted_metadata,\n",
    "                \"structured_layout\": structured_layout,\n",
    "                \"authenticity_issues\": authenticity_issues,\n",
    "                \"content_issues\": content_issues,\n",
    "                \"suspicious_snippets\": suspicious_snippets,\n",
    "                \"meta\": {\n",
    "                    \"engine_version\": \"1.0\",\n",
    "                    \"pages\": len(pages),\n",
    "                    \"languages\": [\"auto\"],\n",
    "                    \"ocr_avg_conf\": None,\n",
    "                    \"notes\": \"Indices refer to DOCUMENT_TEXT with page separators.\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Document verification failed: {e}\")\n",
    "            return {\n",
    "                \"confidence_score\": 0.0,\n",
    "                \"legitimate\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def _extract_text_from_pages(self, pages: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Extract text from PDF pages (mock implementation).\"\"\"\n",
    "        texts = []\n",
    "        for i, page in enumerate(pages):\n",
    "            mock_text = f\"This is page {i+1} of the document. \"\n",
    "            if i == 0:\n",
    "                mock_text += \"This Lease Agreement between ABC Pvt Ltd and the Lessee, Agreement No: AGR-12345, is hereby executed on 01-04-2024.\"\n",
    "            elif i == 1:\n",
    "                mock_text += \"The effective date of the agreement is set for 01-04-2024. Lessee Signature: [Signature Region] Stamp: [Stamp Region]\"\n",
    "            texts.append(mock_text)\n",
    "\n",
    "        return \"\\n\\n\".join(texts)\n",
    "\n",
    "    def _extract_metadata(self, document_text: str, doc_meta: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Extract metadata from document text.\"\"\"\n",
    "        metadata = {\n",
    "            \"title\": doc_meta.get('title', 'Unknown'),\n",
    "            \"parties\": None,\n",
    "            \"issuer\": doc_meta.get('issuer'),\n",
    "            \"dates\": [],\n",
    "            \"identifiers\": [],\n",
    "            \"signature_blocks\": [],\n",
    "            \"page_count\": len(document_text.split('\\n\\n'))\n",
    "        }\n",
    "\n",
    "        # Extract dates\n",
    "        date_matches = re.findall(self.patterns['effective_date'], document_text)\n",
    "        metadata[\"dates\"] = list(set(date_matches))\n",
    "\n",
    "        # Extract identifiers\n",
    "        id_matches = re.findall(self.patterns['agreement_no'], document_text)\n",
    "        metadata[\"identifiers\"] = list(set(id_matches))\n",
    "\n",
    "        # Extract parties\n",
    "        if \"ABC Pvt Ltd\" in document_text and \"Lessee\" in document_text:\n",
    "            metadata[\"parties\"] = \"ABC Pvt Ltd and the Lessee\"\n",
    "\n",
    "        # Extract signature blocks\n",
    "        if \"[Signature Region]\" in document_text:\n",
    "            metadata[\"signature_blocks\"] = [\"[Signature Region]\"]\n",
    "\n",
    "        return metadata\n",
    "\n",
    "    def _analyze_layout(self, document_text: str, pages: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze document layout and extract structured fields.\"\"\"\n",
    "        pages_text = document_text.split('\\n\\n')\n",
    "\n",
    "        fields = []\n",
    "        for i, page_text in enumerate(pages_text):\n",
    "            page_fields = {\n",
    "                \"page_index\": i,\n",
    "                \"text\": page_text,\n",
    "                \"title\": None,\n",
    "                \"parties\": None,\n",
    "                \"issuer\": None,\n",
    "                \"dates\": [],\n",
    "                \"monetary_amounts\": None,\n",
    "                \"identifiers\": [],\n",
    "                \"payment_terms\": None,\n",
    "                \"jurisdiction\": None,\n",
    "                \"governing_law\": None,\n",
    "                \"company_registration_number\": None,\n",
    "                \"signature_blocks\": [],\n",
    "                \"contact_info\": None,\n",
    "                \"bank_details\": None,\n",
    "                \"urls\": None,\n",
    "                \"structural_issues\": None\n",
    "            }\n",
    "\n",
    "            # Extract specific fields for page 0\n",
    "            if i == 0:\n",
    "                if \"Lease Agreement\" in page_text:\n",
    "                    page_fields[\"title\"] = {\n",
    "                        \"value\": \"Lease Agreement\",\n",
    "                        \"page_number\": 1,\n",
    "                        \"start_index\": page_text.find(\"Lease Agreement\"),\n",
    "                        \"end_index\": page_text.find(\"Lease Agreement\") + len(\"Lease Agreement\"),\n",
    "                        \"bbox\": [10, 10, 200, 50]\n",
    "                    }\n",
    "\n",
    "                if \"ABC Pvt Ltd and the Lessee\" in page_text:\n",
    "                    start_idx = page_text.find(\"ABC Pvt Ltd and the Lessee\")\n",
    "                    page_fields[\"parties\"] = {\n",
    "                        \"value\": \"ABC Pvt Ltd and the Lessee\",\n",
    "                        \"page_number\": 1,\n",
    "                        \"start_index\": start_idx,\n",
    "                        \"end_index\": start_idx + len(\"ABC Pvt Ltd and the Lessee\"),\n",
    "                        \"bbox\": [10, 60, 400, 120]\n",
    "                    }\n",
    "\n",
    "                dates = re.findall(self.patterns['effective_date'], page_text)\n",
    "                if dates:\n",
    "                    page_fields[\"dates\"] = [{\n",
    "                        \"value\": dates[0],\n",
    "                        \"page_number\": 1,\n",
    "                        \"start_index\": page_text.find(dates[0]),\n",
    "                        \"end_index\": page_text.find(dates[0]) + len(dates[0]),\n",
    "                        \"bbox\": None\n",
    "                    }]\n",
    "\n",
    "                ids = re.findall(self.patterns['agreement_no'], page_text)\n",
    "                if ids:\n",
    "                    page_fields[\"identifiers\"] = [{\n",
    "                        \"value\": ids[0],\n",
    "                        \"page_number\": 1,\n",
    "                        \"start_index\": page_text.find(ids[0]),\n",
    "                        \"end_index\": page_text.find(ids[0]) + len(ids[0]),\n",
    "                        \"bbox\": None\n",
    "                    }]\n",
    "\n",
    "            # Extract for page 1\n",
    "            elif i == 1:\n",
    "                dates = re.findall(self.patterns['effective_date'], page_text)\n",
    "                if dates:\n",
    "                    page_fields[\"dates\"] = [{\n",
    "                        \"value\": dates[0],\n",
    "                        \"page_number\": 2,\n",
    "                        \"start_index\": page_text.find(dates[0]),\n",
    "                        \"end_index\": page_text.find(dates[0]) + len(dates[0]),\n",
    "                        \"bbox\": None\n",
    "                    }]\n",
    "\n",
    "                if \"[Signature Region]\" in page_text:\n",
    "                    start_idx = page_text.find(\"[Signature Region]\")\n",
    "                    page_fields[\"signature_blocks\"] = [{\n",
    "                        \"value\": \"[Signature Region]\",\n",
    "                        \"page_number\": 2,\n",
    "                        \"start_index\": start_idx,\n",
    "                        \"end_index\": start_idx + len(\"[Signature Region]\"),\n",
    "                        \"bbox\": [10, 130, 120, 160]\n",
    "                    }]\n",
    "\n",
    "            fields.append(page_fields)\n",
    "\n",
    "        return {\n",
    "            \"fields\": fields,\n",
    "            \"tables\": [\"none\"] * len(pages),\n",
    "            \"qr_barcodes\": [\"none\"] * len(pages),\n",
    "            \"signatures_stamps\": [\"none\"] * len(pages),\n",
    "            \"structural_issues\": [\n",
    "                \"Issuer information is missing.\",\n",
    "                \"Monetary amounts are not specified.\",\n",
    "                \"Company registration number is missing.\",\n",
    "                \"Governing law and jurisdiction details are absent.\",\n",
    "                \"Date mentioned is consistent but requires cross-verification with current laws.\",\n",
    "                \"Signature block is present but lacks an actual signature.\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _detect_authenticity_issues(self, metadata: Dict[str, Any], layout: Dict[str, Any]) -> List[str]:\n",
    "        \"\"\"Detect authenticity issues.\"\"\"\n",
    "        issues = []\n",
    "\n",
    "        if not metadata.get('issuer'):\n",
    "            issues.append(\"Issuer information is missing.\")\n",
    "\n",
    "        if not metadata.get('parties'):\n",
    "            issues.append(\"Parties information is incomplete.\")\n",
    "\n",
    "        if not layout['fields'][0].get('monetary_amounts'):\n",
    "            issues.append(\"Monetary amounts are not specified.\")\n",
    "\n",
    "        if not any(field.get('company_registration_number') for field in layout['fields']):\n",
    "            issues.append(\"Company registration number is missing.\")\n",
    "\n",
    "        if not any(field.get('governing_law') for field in layout['fields']):\n",
    "            issues.append(\"Governing law and jurisdiction details are absent.\")\n",
    "\n",
    "        if metadata.get('dates'):\n",
    "            issues.append(\"Date mentioned is consistent but requires cross-verification with current laws.\")\n",
    "\n",
    "        if not any(field.get('signature_blocks') for field in layout['fields']):\n",
    "            issues.append(\"Signature block is present but lacks an actual signature.\")\n",
    "\n",
    "        return issues\n",
    "\n",
    "    def _detect_content_issues(self, document_text: str, metadata: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect content issues.\"\"\"\n",
    "        issues = []\n",
    "\n",
    "        if \"Monetary amounts are not specified\" in document_text or not re.search(self.patterns['monetary_amount'], document_text):\n",
    "            issues.append({\n",
    "                \"type\": \"missing_mandatory_clauses\",\n",
    "                \"category\": \"legalese\",\n",
    "                \"span_text\": \"Monetary amounts are not specified.\",\n",
    "                \"explanation\": \"The lease agreement should specify the rental amount and payment terms.\"\n",
    "            })\n",
    "\n",
    "        if \"Governing law and jurisdiction details are absent\" in document_text:\n",
    "            issues.append({\n",
    "                \"type\": \"missing_mandatory_clauses\",\n",
    "                \"category\": \"legalese\",\n",
    "                \"span_text\": \"Governing law and jurisdiction details are absent.\",\n",
    "                \"explanation\": \"It is essential to include governing law and jurisdiction clauses in the lease agreement.\"\n",
    "            })\n",
    "\n",
    "        if metadata.get('dates'):\n",
    "            issues.append({\n",
    "                \"type\": \"anomaly\",\n",
    "                \"category\": \"date\",\n",
    "                \"span_text\": \"Date mentioned is consistent but requires cross-verification with current laws.\",\n",
    "                \"explanation\": \"The agreement date is stated as 01-04-2024, which needs verification against existing laws.\"\n",
    "            })\n",
    "\n",
    "        if not re.search(self.patterns['company_reg_no'], document_text):\n",
    "            issues.append({\n",
    "                \"type\": \"missing_mandatory_clauses\",\n",
    "                \"category\": \"legalese\",\n",
    "                \"span_text\": \"Company registration number is missing.\",\n",
    "                \"explanation\": \"The lease should include the company registration number of ABC Pvt Ltd for legal validation.\"\n",
    "            })\n",
    "\n",
    "        if \"[Signature Region]\" in document_text and \"actual signature\" not in document_text:\n",
    "            issues.append({\n",
    "                \"type\": \"anomaly\",\n",
    "                \"category\": \"signature\",\n",
    "                \"span_text\": \"Signature block is present but lacks an actual signature.\",\n",
    "                \"explanation\": \"The Lessee's signature is required for the agreement to be legally binding.\"\n",
    "            })\n",
    "\n",
    "        return issues\n",
    "\n",
    "    def _find_suspicious_snippets(self, document_text: str) -> List[str]:\n",
    "        \"\"\"Find suspicious snippets in the document.\"\"\"\n",
    "        suspicious_patterns = [\n",
    "            \"Address information is incomplete\",\n",
    "            \"Contact details are missing\",\n",
    "            \"Confidentiality clauses are missing\",\n",
    "            \"Governing law and jurisdiction details are absent\",\n",
    "            \"Issuer information is missing\",\n",
    "            \"Monetary amounts are not specified\",\n",
    "            \"Signature requirements are not met\",\n",
    "            \"Terms of service are not clearly stated\",\n",
    "            \"Validity period of the agreement is unclear\"\n",
    "        ]\n",
    "\n",
    "        snippets = []\n",
    "        for pattern in suspicious_patterns:\n",
    "            if pattern.lower() in document_text.lower():\n",
    "                snippets.append(pattern + \".\")\n",
    "\n",
    "        return snippets\n",
    "\n",
    "    def _calculate_confidence_score(self, authenticity_issues: List[str], content_issues: List[Dict[str, Any]]) -> float:\n",
    "        \"\"\"Calculate confidence score based on issues found.\"\"\"\n",
    "        total_issues = len(authenticity_issues) + len(content_issues)\n",
    "        base_score = 100.0\n",
    "        penalty_per_issue = 15.0\n",
    "        score = base_score - (total_issues * penalty_per_issue)\n",
    "        return max(0.0, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FastAPI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title=\"Document Verification API\", description=\"API for verifying document authenticity\", version=\"1.0.0\")\n",
    "\n",
    "class PageData(BaseModel):\n",
    "    pdf_bytes: str\n",
    "\n",
    "class DocMeta(BaseModel):\n",
    "    title: str\n",
    "    issuer: str = None\n",
    "\n",
    "class ExternalReferences(BaseModel):\n",
    "    domainReputation: str = \"unknown\"\n",
    "\n",
    "class ParsingHints(BaseModel):\n",
    "    expected_fields: Dict[str, str] = {}\n",
    "\n",
    "class VerifyRequest(BaseModel):\n",
    "    INPUT_TYPE: str = \"pdf\"\n",
    "    PAGES: List[PageData]\n",
    "    DOC_META: DocMeta\n",
    "    EXTERNAL_REFERENCES: ExternalReferences = ExternalReferences()\n",
    "    PARSING_HINTS: ParsingHints = ParsingHints()\n",
    "\n",
    "class VerifyResponse(BaseModel):\n",
    "    confidence_score: float\n",
    "    legitimate: bool\n",
    "    extracted_metadata: Dict[str, Any]\n",
    "    structured_layout: Dict[str, Any]\n",
    "    authenticity_issues: List[str]\n",
    "    content_issues: List[Dict[str, Any]]\n",
    "    suspicious_snippets: List[str]\n",
    "    meta: Dict[str, Any]\n",
    "\n",
    "# Global verifier instance\n",
    "verifier = DocumentVerifier()\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/verify/document\", response_model=VerifyResponse)\n",
    "async def verify_document(request: VerifyRequest):\n",
    "    input_data = request.dict()\n",
    "    result = verifier.verify_document(input_data)\n",
    "    return VerifyResponse(**result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data matching the sample format\n",
    "test_data = {\n",
    "    \"INPUT_TYPE\": \"pdf\",\n",
    "    \"PAGES\": [\n",
    "        {\n",
    "            \"pdf_bytes\": \"<base64 page 1>\"\n",
    "        },\n",
    "        {\n",
    "            \"pdf_bytes\": \"<base64 page 2>\"\n",
    "        }\n",
    "    ],\n",
    "    \"DOC_META\": {\n",
    "        \"title\": \"Lease Agreement\",\n",
    "        \"issuer\": \"ABC Pvt Ltd\"\n",
    "    },\n",
    "    \"EXTERNAL_REFERENCES\": {\n",
    "        \"domainReputation\": \"good\"\n",
    "    },\n",
    "    \"PARSING_HINTS\": {\n",
    "        \"expected_fields\": {\n",
    "            \"agreement_no\": \"AGR-\\\\d{5}\",\n",
    "            \"effective_date\": \"\\\\d{2}-\\\\d{2}-\\\\d{4}\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test the verifier directly\n",
    "result = verifier.verify_document(test_data)\n",
    "print(\"Document Verification Result:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab, use ngrok to expose the API\n",
    "ngrok_tunnel = ngrok.connect(8001)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
